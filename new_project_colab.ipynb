{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "new_project_colab.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "pycharm-c0a3a0b1",
   "language": "python",
   "display_name": "PyCharm (ir_proj)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dexW2VM8-zua",
    "outputId": "2611c15b-95a7-4e53-ad4d-deb741e6031d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\guyyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import Counter, OrderedDict\n",
    "import itertools\n",
    "from itertools import islice, count, groupby\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from time import time\n",
    "from timeit import timeit\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import storage\n",
    "import math\n",
    "import hashlib\n",
    "import builtins\n",
    "def _hash(s):\n",
    "    return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from inverted_index_colab import *"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# These will already be installed in the testing environment so disregard the \n",
    "# amount of time (~1 minute) it takes to install. \n",
    "!pip install -q pyspark\n",
    "!pip install -U -q PyDrive\n",
    "!apt-get update -qq\n",
    "!apt install openjdk-8-jdk-headless -qq\n",
    "!pip install -q graphframes\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "graphframes_jar = 'https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.2-s_2.12/graphframes-0.8.2-spark3.2-s_2.12.jar'\n",
    "spark_jars = '/usr/local/lib/python3.7/dist-packages/pyspark/jars'\n",
    "!wget -N -P $spark_jars $graphframes_jar"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIgXCCs2_Bl1",
    "outputId": "d79a9d50-9fde-4335-b0e9-5dbdd64a9a46"
   },
   "execution_count": 6,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-28a0344c7e14>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-6-28a0344c7e14>\"\u001B[1;36m, line \u001B[1;32m3\u001B[0m\n\u001B[1;33m    pip install -q pyspark\u001B[0m\n\u001B[1;37m        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from graphframes import *"
   ],
   "metadata": {
    "id": "EDY9b6Cz_J5H"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Initializing spark context\n",
    "# create a spark context and session\n",
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sc.addPyFile(str(Path(spark_jars) / Path(graphframes_jar).name))\n",
    "spark = SparkSession.builder.getOrCreate()"
   ],
   "metadata": {
    "id": "Rc4z-XMm_MWR"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Authenticate your user\n",
    "# The authentication should be done with the email connected to your GCP account\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ],
   "metadata": {
    "id": "8U1kZIAH_QVy"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Copy one wikidumps files \n",
    "import os\n",
    "from pathlib import Path\n",
    "from google.colab import auth\n",
    "\n",
    "project_id = 'core-period-321814'\n",
    "!gcloud config set project {project_id}\n",
    "\n",
    "data_bucket_name = 'wikidata_preprocessed'\n",
    "try:\n",
    "    if os.environ[\"wikidata_preprocessed\"] is not None:\n",
    "        pass  \n",
    "except:\n",
    "      !mkdir wikidumps\n",
    "      !gsutil cp gs://{data_bucket_name}/multistream1_preprocessed.parquet \"wikidumps/\" \n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQEE4Mf__Utb",
    "outputId": "36ecbcc4-b295-4c05-ea0d-8f04f296c1a2"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updated property [core/project].\n",
      "\u001B[1;33mWARNING:\u001B[0m You do not appear to have access to project [core-period-321814] or it does not exist.\n",
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n",
      "Copying gs://wikidata_preprocessed/multistream1_preprocessed.parquet...\n",
      "- [1 files][316.7 MiB/316.7 MiB]                                                \n",
      "Operation completed over 1 objects/316.7 MiB.                                    \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path \n",
    "import os\n",
    "\n",
    "try:\n",
    "    if os.environ[\"wikidata_preprocessed\"] is not None:\n",
    "      path = os.environ[\"wikidata_preprocessed\"]+\"/wikidumps/*\"\n",
    "except:\n",
    "      path = \"wikidumps/*\"\n",
    "\n",
    "parquetFile = spark.read.parquet(path)"
   ],
   "metadata": {
    "id": "QIPsyuyd_arc"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "parquetFile.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-se9VCWJffWJ",
    "outputId": "4919b61b-355a-4bc2-a25c-fcf6da5d5076"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|               title|                text|         anchor_text|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "| 12|           Anarchism|'''Anarchism''' i...|[{23040, politica...|\n",
      "| 25|              Autism|'''Autism''' is a...|[{492271, Clinica...|\n",
      "| 39|              Albedo|thumb|upright=1.3...|[{679294, diffuse...|\n",
      "|290|                   A|'''A''', or '''a'...|[{290, See below}...|\n",
      "|303|             Alabama|'''Alabama''' () ...|[{351590, Yellowh...|\n",
      "|305|            Achilles|thumb|260px|Ancie...|[{1076007, potter...|\n",
      "|307|     Abraham Lincoln|'''Abraham Lincol...|[{1827174, Alexan...|\n",
      "|308|           Aristotle|'''Aristotle''' (...|[{1389981, bust},...|\n",
      "|309|An American in Paris|'''''An American ...|[{13066, George G...|\n",
      "|316|Academy Award for...|The '''Academy Aw...|[{39842, Academy ...|\n",
      "|324|      Academy Awards|The '''Academy Aw...|[{649481, film in...|\n",
      "|330|             Actrius|'''''Actresses'''...|[{5282, Catalan},...|\n",
      "|332|     Animalia (book)|'''''Animalia''''...|[{2511084, Graeme...|\n",
      "|334|International Ato...|'''International ...|[{25453985, atomi...|\n",
      "|336|            Altruism|thumb|Giving alms...|[{657573, alms}, ...|\n",
      "|339|            Ayn Rand|'''Alice O'Connor...|[{24320051, St. P...|\n",
      "|340|        Alain Connes|'''Alain Connes''...|[{1201522, Dragui...|\n",
      "|344|          Allan Dwan|'''Allan Dwan''' ...|[{64646, Toronto}...|\n",
      "|358|             Algeria|'''Algeria''', of...|[{803, Arabic}, {...|\n",
      "|359|List of Atlas Shr...|This is a list of...|[{339, Ayn Rand},...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# take the 'text' and 'id' or the first 1000 rows and create an RDD from it\n",
    "doc_text_pairs = parquetFile.limit(1000).select(\"text\", \"id\").rdd\n",
    "# take the 'title' and 'id' or the first 1000 rows and create an RDD from it\n",
    "doc_title_pairs = parquetFile.limit(1000).select(\"title\", \"id\").rdd\n",
    "# take the 'anchor text' and 'id' or the first 1000 rows and create an RDD from it\n",
    "doc_anchor_text_id_pairs = parquetFile.limit(1000).select(\"id\", \"anchor_text\").rdd"
   ],
   "metadata": {
    "id": "SicpREcCDG-w"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "doc_anchor_text_pairs=doc_anchor_text_id_pairs.map(lambda x:(\" \".join([t[1] for t in x[1]]), x[0]))"
   ],
   "metadata": {
    "id": "mkvgwPg51Iis"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "english_stopwords = frozenset(stopwords.words('english'))\n",
    "RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n",
    "\n",
    "def word_count(text, id):\n",
    "  ''' Count the frequency of each word in `text` (tf) that is not included in \n",
    "  `all_stopwords` and return entries that will go into our posting lists. \n",
    "  Parameters:\n",
    "  -----------\n",
    "    text: str\n",
    "      Text of one document\n",
    "    id: int\n",
    "      Document id\n",
    "  Returns:\n",
    "  --------\n",
    "    List of tuples\n",
    "      A list of (token, (doc_id, tf)) pairs \n",
    "      for example: [(\"Anarchism\", (12, 5)), ...]\n",
    "  '''\n",
    "  tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n",
    "  my_count=Counter(tokens)\n",
    "  words_list=[(x,(id,my_count[x])) for x in my_count if x not in english_stopwords]\n",
    "  return words_list"
   ],
   "metadata": {
    "id": "G7JleAOIbiYe"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def doc_NF(text, id):\n",
    "\n",
    "  tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n",
    "  my_count=Counter(tokens)\n",
    "  # words_list=[(x,(id,my_count[x])) for x in my_count if x not in english_stopwords]\n",
    "  sum_square=0\n",
    "  for c in my_count:\n",
    "    sum_square+=my_count[c]**2\n",
    "  if sum_square==0:\n",
    "    return(id,(0,len(text.split(\" \"))))\n",
    "  return (id,(1/math.sqrt(sum_square),len(tokens)))"
   ],
   "metadata": {
    "id": "WpXtDePxcPHO"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def reduce_word_counts(unsorted_pl):\n",
    "  ''' Returns a sorted posting list by wiki_id.\n",
    "  Parameters:\n",
    "  -----------\n",
    "    unsorted_pl: list of tuples\n",
    "      A list of (wiki_id, tf) tuples \n",
    "  Returns:\n",
    "  --------\n",
    "    list of tuples\n",
    "      A sorted posting list.\n",
    "  '''\n",
    "  list_sort=sorted(unsorted_pl)\n",
    "  return list_sort"
   ],
   "metadata": {
    "id": "3rtD7P5td5a2"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_df(postings):\n",
    "  ''' Takes a posting list RDD and calculate the df for each token.\n",
    "  Parameters:\n",
    "  -----------\n",
    "    postings: RDD\n",
    "      An RDD where each element is a (token, posting_list) pair.\n",
    "  Returns:\n",
    "  --------\n",
    "    RDD\n",
    "      An RDD where each element is a (token, df) pair.\n",
    "  '''\n",
    "  my_rdd=postings.map(lambda w: (w[0],len(w[1])))\n",
    "  return my_rdd"
   ],
   "metadata": {
    "id": "YGdTaIsJebDT"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import inverted_index_colab\n",
    "NUM_BUCKETS = 124\n",
    "def token2bucket_id(token):\n",
    "  return int(_hash(token),16) % NUM_BUCKETS\n",
    "\n",
    "def partition_postings_and_write(postings,base_dir):\n",
    "  ''' A function that partitions the posting lists into buckets, writes out \n",
    "  all posting lists in a bucket to disk, and returns the posting locations for \n",
    "  each bucket. Partitioning should be done through the use of `token2bucket` \n",
    "  above. Writing to disk should use the function  `write_a_posting_list`, a \n",
    "  static method implemented in inverted_index_colab.py under the InvertedIndex \n",
    "  class. \n",
    "  Parameters:\n",
    "  -----------\n",
    "    postings: RDD\n",
    "      An RDD where each item is a (w, posting_list) pair.\n",
    "  Returns:\n",
    "  --------\n",
    "    RDD\n",
    "      An RDD where each item is a posting locations dictionary for a bucket. The\n",
    "      posting locations maintain a list for each word of file locations and \n",
    "      offsets its posting list was written to. See `write_a_posting_list` for \n",
    "      more details.\n",
    "  '''\n",
    "  my_rdd=postings.map(lambda x:(token2bucket_id(x[0]),x)).groupByKey().mapValues(list).mapValues(sorted).map(lambda t: inverted_index_colab.InvertedIndex.write_a_posting_list(t,base_dir))\n",
    "  \n",
    "\n",
    "  return my_rdd"
   ],
   "metadata": {
    "id": "smVRnfDEesAc"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# create directories for the different indices \n",
    "!mkdir body_index title_index anchor_index"
   ],
   "metadata": {
    "id": "9imY94pfivAw"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# prepare all the data for the body index\n",
    "##########################################\n",
    "# calculate df for each term in rhe vocabulary:\n",
    "word_counts = doc_text_pairs.flatMap(lambda x: word_count(x[0], x[1]))\n",
    "postings = word_counts.groupByKey().mapValues(reduce_word_counts)\n",
    "postings_filtered = postings.filter(lambda x: len(x[1])>10)\n",
    "w2df = calculate_df(postings_filtered)\n",
    "w2df_dict = w2df.collectAsMap()\n",
    "# caculate the NF tns the document length for each document:\n",
    "nf=doc_text_pairs.map(lambda x: doc_NF(x[0], x[1]))\n",
    "nf_dict = nf.collectAsMap()\n",
    "# createing posting list for each term\n",
    "posting_locs_list = partition_postings_and_write(postings_filtered,'body_index').collect()\n",
    "# merge the posting locations into a single dict and run more tests\n",
    "super_posting_locs = defaultdict(list)\n",
    "for posting_loc in posting_locs_list:\n",
    "  for k, v in posting_loc.items():\n",
    "    super_posting_locs[k].extend(v)"
   ],
   "metadata": {
    "id": "DDrExxRSex9b"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create inverted index instance\n",
    "inverted_body = InvertedIndex()\n",
    "# Adding the posting locations dictionary to the inverted index\n",
    "inverted_body.posting_locs = super_posting_locs\n",
    "# Add the token - df dictionary to the inverted index\n",
    "inverted_body.df = w2df_dict\n",
    "# Add the NF dictionary to the inverted index\n",
    "inverted_body.NF=nf_dict\n",
    "# write the global stats out\n",
    "inverted_body.write_index('body_index', 'body_index')"
   ],
   "metadata": {
    "id": "OLV3Nl1nvp6-"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "w2df_dict"
   ],
   "metadata": {
    "id": "ZiMqAt0Lq5sr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "88946083-da7e-4211-f353-5b7d878bd9cf"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'political': 290,\n",
       " 'philosophy': 135,\n",
       " 'movement': 231,\n",
       " 'sceptical': 12,\n",
       " 'authority': 172,\n",
       " 'rejects': 16,\n",
       " 'involuntary': 12,\n",
       " 'forms': 286,\n",
       " 'hierarchy': 37,\n",
       " 'calls': 105,\n",
       " 'abolition': 32,\n",
       " 'state': 468,\n",
       " 'holds': 126,\n",
       " 'undesirable': 13,\n",
       " 'unnecessary': 34,\n",
       " 'harmful': 25,\n",
       " 'historically': 136,\n",
       " 'usually': 364,\n",
       " 'described': 358,\n",
       " 'alongside': 121,\n",
       " 'libertarian': 15,\n",
       " 'wing': 48,\n",
       " 'socialism': 20,\n",
       " 'socialist': 41,\n",
       " 'strong': 293,\n",
       " 'historical': 281,\n",
       " 'association': 231,\n",
       " 'history': 638,\n",
       " 'anarchy': 13,\n",
       " 'goes': 107,\n",
       " 'back': 412,\n",
       " 'prehistory': 17,\n",
       " 'humans': 127,\n",
       " 'arguably': 38,\n",
       " 'lived': 204,\n",
       " 'societies': 55,\n",
       " 'long': 464,\n",
       " 'establishment': 102,\n",
       " 'formal': 141,\n",
       " 'states': 554,\n",
       " 'realms': 14,\n",
       " 'empires': 30,\n",
       " 'rise': 200,\n",
       " 'organised': 43,\n",
       " 'hierarchical': 17,\n",
       " 'bodies': 115,\n",
       " 'toward': 162,\n",
       " 'also': 897,\n",
       " 'rose': 113,\n",
       " '19th': 217,\n",
       " 'century': 496,\n",
       " 'emerged': 114,\n",
       " 'latter': 282,\n",
       " 'half': 294,\n",
       " 'first': 805,\n",
       " 'decades': 162,\n",
       " '20th': 226,\n",
       " 'anarchist': 14,\n",
       " 'flourished': 33,\n",
       " 'parts': 307,\n",
       " 'world': 532,\n",
       " 'significant': 338,\n",
       " 'role': 315,\n",
       " 'workers': 115,\n",
       " 'struggles': 30,\n",
       " 'emancipation': 21,\n",
       " 'various': 474,\n",
       " 'schools': 136,\n",
       " 'thought': 320,\n",
       " 'formed': 297,\n",
       " 'period': 403,\n",
       " 'taken': 335,\n",
       " 'part': 621,\n",
       " 'several': 612,\n",
       " 'revolutions': 20,\n",
       " 'notably': 181,\n",
       " 'spanish': 186,\n",
       " 'civil': 222,\n",
       " 'war': 455,\n",
       " 'whose': 341,\n",
       " 'end': 470,\n",
       " 'marked': 162,\n",
       " 'classical': 205,\n",
       " 'era': 214,\n",
       " 'last': 439,\n",
       " '21st': 89,\n",
       " 'employs': 33,\n",
       " 'diversity': 58,\n",
       " 'tactics': 29,\n",
       " 'order': 475,\n",
       " 'meet': 142,\n",
       " 'ideal': 81,\n",
       " 'ends': 111,\n",
       " 'broadly': 43,\n",
       " 'separated': 132,\n",
       " 'revolutionary': 88,\n",
       " 'evolutionary': 39,\n",
       " 'overlap': 21,\n",
       " 'two': 750,\n",
       " 'merely': 99,\n",
       " 'descriptive': 22,\n",
       " 'aim': 79,\n",
       " 'bring': 146,\n",
       " 'violent': 77,\n",
       " 'turn': 229,\n",
       " 'past': 192,\n",
       " 'society': 281,\n",
       " 'would': 624,\n",
       " 'like': 504,\n",
       " 'criticism': 105,\n",
       " 'played': 204,\n",
       " 'diverse': 91,\n",
       " 'areas': 249,\n",
       " 'human': 321,\n",
       " 'criticisms': 29,\n",
       " 'include': 468,\n",
       " 'claims': 173,\n",
       " 'internally': 36,\n",
       " 'inconsistent': 33,\n",
       " 'utopian': 11,\n",
       " 'etymology': 123,\n",
       " 'terminology': 81,\n",
       " 'definition': 146,\n",
       " 'thumb': 709,\n",
       " 'wilhelm': 73,\n",
       " 'example': 443,\n",
       " 'writer': 200,\n",
       " 'added': 271,\n",
       " 'theory': 215,\n",
       " 'without': 439,\n",
       " 'using': 418,\n",
       " 'exact': 105,\n",
       " 'term': 350,\n",
       " 'etymological': 11,\n",
       " 'origin': 213,\n",
       " 'ancient': 306,\n",
       " 'greek': 361,\n",
       " 'meaning': 301,\n",
       " 'ruler': 95,\n",
       " 'composed': 189,\n",
       " 'prefix': 30,\n",
       " 'word': 287,\n",
       " 'leader': 216,\n",
       " 'suffix': 34,\n",
       " 'denotes': 32,\n",
       " 'ideological': 27,\n",
       " 'current': 257,\n",
       " 'favours': 15,\n",
       " 'appears': 243,\n",
       " 'english': 424,\n",
       " '1642': 14,\n",
       " '1539': 14,\n",
       " 'early': 629,\n",
       " 'emphasised': 16,\n",
       " 'sense': 202,\n",
       " 'disorder': 34,\n",
       " 'factions': 33,\n",
       " 'within': 502,\n",
       " 'french': 366,\n",
       " 'revolution': 140,\n",
       " 'labelled': 30,\n",
       " 'opponents': 66,\n",
       " 'although': 538,\n",
       " 'accused': 92,\n",
       " 'shared': 147,\n",
       " 'many': 670,\n",
       " 'views': 119,\n",
       " 'later': 639,\n",
       " 'revolutionaries': 13,\n",
       " 'william': 299,\n",
       " '1756': 18,\n",
       " '1836': 59,\n",
       " '1808': 39,\n",
       " '1871': 71,\n",
       " 'contribute': 53,\n",
       " 'doctrines': 40,\n",
       " 'next': 344,\n",
       " 'generation': 132,\n",
       " 'use': 572,\n",
       " 'describing': 105,\n",
       " 'beliefs': 74,\n",
       " 'philosopher': 137,\n",
       " 'call': 167,\n",
       " '1809': 42,\n",
       " '1865': 87,\n",
       " 'marking': 49,\n",
       " 'birth': 203,\n",
       " 'mid-19th': 23,\n",
       " 'since': 597,\n",
       " '1890s': 27,\n",
       " 'beginning': 325,\n",
       " 'france': 273,\n",
       " 'often': 518,\n",
       " 'used': 648,\n",
       " 'synonym': 26,\n",
       " 'still': 503,\n",
       " 'common': 440,\n",
       " 'outside': 278,\n",
       " 'united': 497,\n",
       " 'hand': 261,\n",
       " 'refer': 212,\n",
       " 'referring': 113,\n",
       " 'largely': 223,\n",
       " 'synonymous': 29,\n",
       " 'recently': 179,\n",
       " 'wider': 69,\n",
       " 'adoption': 63,\n",
       " 'disparate': 11,\n",
       " 'groups': 258,\n",
       " 'including': 626,\n",
       " 'new': 712,\n",
       " 'left': 516,\n",
       " 'associate': 69,\n",
       " 'socialists': 11,\n",
       " 'vanguard': 13,\n",
       " 'party': 194,\n",
       " 'well': 596,\n",
       " 'extreme': 116,\n",
       " 'liberals': 17,\n",
       " 'primarily': 215,\n",
       " 'concerned': 114,\n",
       " 'liberties': 20,\n",
       " 'additionally': 125,\n",
       " 'avoid': 162,\n",
       " 'negative': 123,\n",
       " 'connotations': 12,\n",
       " 'connections': 81,\n",
       " 'matthew': 67,\n",
       " 'adams': 43,\n",
       " 'carl': 103,\n",
       " 'levy': 26,\n",
       " 'write': 148,\n",
       " 'describe': 157,\n",
       " 'describes': 158,\n",
       " 'daniel': 104,\n",
       " 'wrote': 299,\n",
       " 'really': 81,\n",
       " 'abolish': 12,\n",
       " 'exploitation': 25,\n",
       " 'man': 316,\n",
       " 'one': 819,\n",
       " 'streams': 30,\n",
       " 'stream': 53,\n",
       " 'main': 432,\n",
       " 'components': 119,\n",
       " 'concern': 89,\n",
       " 'liberty': 50,\n",
       " 'opposition': 127,\n",
       " 'central': 322,\n",
       " 'defining': 61,\n",
       " 'easy': 89,\n",
       " 'task': 104,\n",
       " 'lot': 69,\n",
       " 'discussion': 94,\n",
       " 'among': 503,\n",
       " 'scholars': 158,\n",
       " 'matter': 169,\n",
       " 'currents': 27,\n",
       " 'perceive': 29,\n",
       " 'slightly': 171,\n",
       " 'differently': 52,\n",
       " 'hence': 118,\n",
       " 'might': 277,\n",
       " 'true': 238,\n",
       " 'say': 182,\n",
       " 'cluster': 35,\n",
       " 'philosophies': 20,\n",
       " 'opposing': 50,\n",
       " 'organisation': 62,\n",
       " 'capitalism': 20,\n",
       " 'nationalism': 26,\n",
       " 'associated': 268,\n",
       " 'institutions': 102,\n",
       " 'conduct': 71,\n",
       " 'relations': 170,\n",
       " 'favour': 70,\n",
       " 'based': 507,\n",
       " 'freedom': 140,\n",
       " 'voluntary': 34,\n",
       " 'however': 645,\n",
       " 'shortcomings': 12,\n",
       " 'conclusion': 74,\n",
       " 'much': 511,\n",
       " 'simply': 220,\n",
       " 'nonetheless': 58,\n",
       " 'major': 451,\n",
       " 'elements': 206,\n",
       " 'rejection': 35,\n",
       " 'apparatus': 27,\n",
       " 'belief': 124,\n",
       " 'nature': 280,\n",
       " 'allows': 158,\n",
       " 'exist': 173,\n",
       " 'progress': 104,\n",
       " 'suggestion': 57,\n",
       " 'act': 276,\n",
       " 'pursue': 51,\n",
       " 'herbert': 58,\n",
       " 'claimed': 203,\n",
       " 'communism': 24,\n",
       " 'peter': 234,\n",
       " 'marshall': 56,\n",
       " 'general': 514,\n",
       " 'closer': 110,\n",
       " 'liberalism': 12,\n",
       " 'finds': 67,\n",
       " 'camp': 95,\n",
       " 'cannot': 200,\n",
       " 'reduced': 186,\n",
       " 'best': 308,\n",
       " 'seen': 367,\n",
       " 'separate': 251,\n",
       " 'distinctive': 64,\n",
       " 'doctrine': 69,\n",
       " 'according': 490,\n",
       " 'jeremy': 24,\n",
       " 'jennings': 13,\n",
       " 'hard': 162,\n",
       " 'conclude': 37,\n",
       " 'ideas': 146,\n",
       " 'basis': 233,\n",
       " 'misunderstanding': 16,\n",
       " 'adds': 63,\n",
       " 'stand': 107,\n",
       " 'individual': 231,\n",
       " 'appear': 242,\n",
       " 'believe': 155,\n",
       " 'already': 243,\n",
       " 'extension': 98,\n",
       " 'community': 207,\n",
       " 'nicolas': 44,\n",
       " 'walter': 119,\n",
       " 'derive': 48,\n",
       " 'always': 271,\n",
       " 'remain': 225,\n",
       " 'whenever': 32,\n",
       " 'reject': 32,\n",
       " 'good': 304,\n",
       " 'either': 389,\n",
       " 'michael': 238,\n",
       " 'newman': 22,\n",
       " 'includes': 281,\n",
       " 'traditions': 106,\n",
       " 'especially': 357,\n",
       " 'tradition': 198,\n",
       " 'following': 538,\n",
       " 'mikhail': 32,\n",
       " 'brian': 69,\n",
       " 'argues': 83,\n",
       " 'misleading': 17,\n",
       " 'create': 240,\n",
       " 'upright': 325,\n",
       " 'zeno': 11,\n",
       " '334': 13,\n",
       " 'republic': 199,\n",
       " 'inspired': 149,\n",
       " 'prehistoric': 27,\n",
       " 'mankind': 29,\n",
       " 'established': 363,\n",
       " 'creation': 176,\n",
       " 'towns': 80,\n",
       " 'cities': 171,\n",
       " 'reaction': 110,\n",
       " 'notable': 214,\n",
       " 'precursors': 18,\n",
       " 'china': 180,\n",
       " 'greece': 140,\n",
       " 'philosophical': 80,\n",
       " 'legitimacy': 32,\n",
       " 'delineated': 12,\n",
       " 'philosophers': 65,\n",
       " 'said': 405,\n",
       " 'attitudes': 30,\n",
       " 'articulated': 21,\n",
       " 'aeschylus': 12,\n",
       " 'sophocles': 13,\n",
       " 'myth': 63,\n",
       " 'illustrate': 27,\n",
       " 'conflict': 142,\n",
       " 'rules': 140,\n",
       " 'set': 459,\n",
       " 'personal': 254,\n",
       " 'autonomy': 49,\n",
       " 'socrates': 15,\n",
       " 'questioned': 58,\n",
       " 'athenian': 25,\n",
       " 'authorities': 99,\n",
       " 'constantly': 45,\n",
       " 'insisted': 57,\n",
       " 'right': 547,\n",
       " 'conscience': 22,\n",
       " 'dismissed': 56,\n",
       " 'law': 260,\n",
       " 'trying': 94,\n",
       " 'live': 212,\n",
       " 'supportive': 17,\n",
       " 'unofficial': 29,\n",
       " 'friendly': 60,\n",
       " 'citizens': 113,\n",
       " 'presence': 206,\n",
       " 'middle': 292,\n",
       " 'ages': 132,\n",
       " 'activity': 185,\n",
       " 'except': 220,\n",
       " 'ascetic': 12,\n",
       " 'religious': 237,\n",
       " 'movements': 91,\n",
       " 'muslim': 81,\n",
       " 'christian': 255,\n",
       " 'europe': 306,\n",
       " 'kind': 163,\n",
       " 'gave': 298,\n",
       " 'empire': 257,\n",
       " 'called': 632,\n",
       " 'monarchy': 44,\n",
       " 'soon': 265,\n",
       " 'executed': 96,\n",
       " 'emperor': 176,\n",
       " 'sects': 13,\n",
       " 'preached': 24,\n",
       " 'developed': 356,\n",
       " 'tendencies': 18,\n",
       " 'renaissance': 78,\n",
       " 'spread': 170,\n",
       " 'humanism': 11,\n",
       " 'rationalism': 11,\n",
       " 'reasoning': 48,\n",
       " 'novelists': 22,\n",
       " 'rather': 379,\n",
       " 'age': 359,\n",
       " 'enlightenment': 40,\n",
       " 'pushed': 65,\n",
       " 'towards': 266,\n",
       " 'social': 237,\n",
       " 'modern': 454,\n",
       " 'partisan': 14,\n",
       " 'saw': 230,\n",
       " 'turning': 81,\n",
       " 'point': 374,\n",
       " 'sentiments': 19,\n",
       " 'throughout': 323,\n",
       " '18th': 122,\n",
       " 'england': 230,\n",
       " 'morally': 16,\n",
       " 'max': 72,\n",
       " 'thinking': 71,\n",
       " 'paved': 25,\n",
       " 'way': 452,\n",
       " 'found': 538,\n",
       " 'fertile': 28,\n",
       " 'soil': 73,\n",
       " 'late': 427,\n",
       " '1870s': 25,\n",
       " 'become': 430,\n",
       " 'well-defined': 11,\n",
       " 'wave': 75,\n",
       " 'unprecedented': 30,\n",
       " 'occurred': 176,\n",
       " '1880': 78,\n",
       " '1914': 121,\n",
       " 'lasted': 97,\n",
       " 'considered': 462,\n",
       " 'golden': 140,\n",
       " 'opposed': 176,\n",
       " 'marxist': 19,\n",
       " 'dictatorship': 14,\n",
       " 'allied': 90,\n",
       " 'international': 374,\n",
       " 'expulsion': 22,\n",
       " 'drawing': 95,\n",
       " 'founded': 280,\n",
       " 'entered': 194,\n",
       " 'class': 211,\n",
       " 'worker': 35,\n",
       " 'union': 273,\n",
       " 'known': 720,\n",
       " '1864': 66,\n",
       " 'unite': 34,\n",
       " 'became': 540,\n",
       " 'force': 287,\n",
       " 'karl': 94,\n",
       " 'marx': 18,\n",
       " 'leading': 310,\n",
       " 'figure': 213,\n",
       " 'member': 287,\n",
       " 'council': 196,\n",
       " 'faction': 39,\n",
       " 'federation': 55,\n",
       " 'followers': 85,\n",
       " 'advocating': 24,\n",
       " 'small': 468,\n",
       " 'property': 178,\n",
       " 'holdings': 23,\n",
       " 'bitter': 36,\n",
       " 'disputes': 54,\n",
       " 'expelled': 43,\n",
       " '1872': 71,\n",
       " 'hague': 23,\n",
       " 'congress': 105,\n",
       " 'treated': 132,\n",
       " 'similarly': 165,\n",
       " 'second': 558,\n",
       " 'ultimately': 160,\n",
       " '1896': 90,\n",
       " 'famously': 31,\n",
       " 'predicted': 64,\n",
       " 'gained': 158,\n",
       " 'power': 376,\n",
       " 'terms': 301,\n",
       " 'response': 213,\n",
       " 'influence': 268,\n",
       " 'russian': 202,\n",
       " 'scientist': 102,\n",
       " 'drew': 82,\n",
       " 'inspiration': 61,\n",
       " 'paris': 169,\n",
       " 'commune': 12,\n",
       " 'advocated': 47,\n",
       " 'free': 284,\n",
       " 'distribution': 134,\n",
       " 'goods': 90,\n",
       " \"one's\": 66,\n",
       " 'needs': 127,\n",
       " 'feature': 157,\n",
       " 'students': 139,\n",
       " 'imported': 46,\n",
       " 'version': 266,\n",
       " 'tokyo': 29,\n",
       " 'rebellious': 21,\n",
       " 'youth': 114,\n",
       " 'countries': 240,\n",
       " 'far': 305,\n",
       " 'east': 331,\n",
       " 'travelling': 30,\n",
       " 'japanese': 157,\n",
       " 'capital': 204,\n",
       " 'study': 282,\n",
       " 'latin': 277,\n",
       " 'america': 256,\n",
       " 'argentina': 46,\n",
       " 'stronghold': 26,\n",
       " 'prominent': 191,\n",
       " 'left-wing': 14,\n",
       " 'ideology': 42,\n",
       " 'time': 678,\n",
       " 'minority': 72,\n",
       " 'adopted': 226,\n",
       " 'violence': 72,\n",
       " 'strategy': 78,\n",
       " 'propaganda': 40,\n",
       " 'deed': 14,\n",
       " 'execution': 69,\n",
       " 'exile': 63,\n",
       " 'penal': 15,\n",
       " 'colonies': 71,\n",
       " 'suppression': 21,\n",
       " 'favoured': 30,\n",
       " 'expression': 103,\n",
       " 'acts': 142,\n",
       " 'even': 515,\n",
       " 'though': 445,\n",
       " 'distanced': 13,\n",
       " 'terrorist': 26,\n",
       " 'came': 379,\n",
       " 'upon': 375,\n",
       " 'attempts': 138,\n",
       " 'made': 616,\n",
       " 'exclude': 18,\n",
       " 'american': 465,\n",
       " 'immigration': 37,\n",
       " '1903': 115,\n",
       " 'exclusion': 25,\n",
       " 'another': 548,\n",
       " 'members': 341,\n",
       " 'army': 268,\n",
       " 'ukraine': 45,\n",
       " 'despite': 312,\n",
       " 'concerns': 94,\n",
       " 'participated': 74,\n",
       " 'white': 295,\n",
       " 'met': 210,\n",
       " 'harsh': 43,\n",
       " 'government': 313,\n",
       " 'moscow': 61,\n",
       " 'fled': 88,\n",
       " 'rebellion': 78,\n",
       " 'struggle': 80,\n",
       " 'territory': 171,\n",
       " 'crushed': 31,\n",
       " 'russia': 168,\n",
       " 'namely': 88,\n",
       " 'synthesis': 58,\n",
       " 'former': 407,\n",
       " 'sought': 144,\n",
       " 'coherent': 21,\n",
       " 'group': 448,\n",
       " 'push': 38,\n",
       " 'anything': 113,\n",
       " 'resemble': 49,\n",
       " 'seeing': 68,\n",
       " 'victories': 63,\n",
       " 'october': 311,\n",
       " 'resulting': 237,\n",
       " 'activists': 39,\n",
       " 'turned': 212,\n",
       " 'communist': 65,\n",
       " 'parties': 97,\n",
       " 'grew': 165,\n",
       " 'expense': 44,\n",
       " 'confederation': 26,\n",
       " 'labour': 62,\n",
       " 'industrial': 125,\n",
       " 'organisations': 33,\n",
       " 'joined': 205,\n",
       " '1936': 128,\n",
       " 'led': 443,\n",
       " 'playing': 110,\n",
       " 'pivotal': 23,\n",
       " 'peasants': 25,\n",
       " 'supported': 207,\n",
       " 'armed': 105,\n",
       " 'militias': 17,\n",
       " 'took': 376,\n",
       " 'control': 324,\n",
       " 'barcelona': 39,\n",
       " 'large': 476,\n",
       " 'rural': 65,\n",
       " 'spain': 163,\n",
       " 'land': 280,\n",
       " 'soviet': 143,\n",
       " 'provided': 274,\n",
       " 'limited': 260,\n",
       " 'assistance': 102,\n",
       " 'result': 403,\n",
       " 'fight': 130,\n",
       " 'communists': 13,\n",
       " 'series': 377,\n",
       " 'events': 285,\n",
       " 'named': 452,\n",
       " 'may': 730,\n",
       " 'days': 336,\n",
       " 'joseph': 165,\n",
       " 'tried': 150,\n",
       " 'seize': 24,\n",
       " 'republicans': 22,\n",
       " 'post-war': 28,\n",
       " 'support': 344,\n",
       " 'efforts': 147,\n",
       " 'form': 511,\n",
       " 'exemplified': 18,\n",
       " 'cooperative': 19,\n",
       " 'severely': 57,\n",
       " 'weakened': 35,\n",
       " '1960s': 144,\n",
       " 'witnessed': 40,\n",
       " 'revival': 60,\n",
       " 'likely': 231,\n",
       " 'caused': 263,\n",
       " 'perceived': 95,\n",
       " 'failure': 138,\n",
       " 'tensions': 32,\n",
       " 'built': 302,\n",
       " 'cold': 131,\n",
       " 'critical': 160,\n",
       " 'environmental': 92,\n",
       " 'peace': 197,\n",
       " 'transition': 75,\n",
       " 'previous': 233,\n",
       " 'punk': 11,\n",
       " 'bands': 47,\n",
       " 'sex': 58,\n",
       " 'feminist': 26,\n",
       " 'returned': 252,\n",
       " 'black': 292,\n",
       " 'began': 411,\n",
       " 'take': 368,\n",
       " 'influenced': 198,\n",
       " 'move': 177,\n",
       " 'demographic': 21,\n",
       " 'coincided': 32,\n",
       " 'gain': 113,\n",
       " 'northern': 266,\n",
       " 'height': 89,\n",
       " 'around': 502,\n",
       " 'popularity': 101,\n",
       " 'anti-war': 12,\n",
       " 'involvement': 68,\n",
       " 'protests': 42,\n",
       " 'trade': 179,\n",
       " 'organization': 167,\n",
       " 'eight': 221,\n",
       " 'economic': 167,\n",
       " 'forum': 35,\n",
       " 'hoc': 20,\n",
       " 'anonymous': 41,\n",
       " 'engaged': 97,\n",
       " 'rioting': 13,\n",
       " 'destruction': 94,\n",
       " 'police': 117,\n",
       " 'pioneered': 43,\n",
       " 'affinity': 25,\n",
       " 'security': 128,\n",
       " 'culture': 254,\n",
       " 'technologies': 68,\n",
       " 'internet': 97,\n",
       " 'event': 198,\n",
       " '1999': 277,\n",
       " 'seattle': 25,\n",
       " 'conference': 111,\n",
       " 'influential': 135,\n",
       " 'development': 334,\n",
       " 'mexico': 119,\n",
       " 'democratic': 92,\n",
       " 'syria': 75,\n",
       " 'commonly': 273,\n",
       " 'facto': 39,\n",
       " 'autonomous': 53,\n",
       " 'region': 287,\n",
       " 'generally': 376,\n",
       " 'grouped': 37,\n",
       " 'owing': 50,\n",
       " 'different': 481,\n",
       " 'origins': 125,\n",
       " 'values': 151,\n",
       " 'evolution': 83,\n",
       " 'positive': 124,\n",
       " 'aiming': 20,\n",
       " 'achieve': 101,\n",
       " 'potential': 184,\n",
       " 'equality': 44,\n",
       " 'ownership': 47,\n",
       " 'chronological': 23,\n",
       " 'green': 181,\n",
       " 'thereafter': 82,\n",
       " 'beyond': 209,\n",
       " 'specific': 242,\n",
       " 'constitute': 55,\n",
       " 'lies': 95,\n",
       " 'lacks': 34,\n",
       " 'moral': 85,\n",
       " 'necessarily': 81,\n",
       " 'accepting': 39,\n",
       " 'imperative': 17,\n",
       " 'eliminate': 60,\n",
       " 'component': 112,\n",
       " 'tolerate': 14,\n",
       " 'existence': 150,\n",
       " 'minimal': 57,\n",
       " 'obligation': 21,\n",
       " 'obey': 18,\n",
       " 'conflicts': 76,\n",
       " 'pays': 14,\n",
       " 'attention': 165,\n",
       " 'arguments': 77,\n",
       " 'ethics': 48,\n",
       " 'emphasis': 91,\n",
       " 'sets': 112,\n",
       " 'apart': 130,\n",
       " 'types': 211,\n",
       " 'placed': 238,\n",
       " 'spectrum': 69,\n",
       " 'economics': 49,\n",
       " 'legal': 155,\n",
       " 'reflect': 90,\n",
       " 'radical': 77,\n",
       " 'interpretations': 54,\n",
       " 'politics': 130,\n",
       " 'theories': 100,\n",
       " 'offer': 133,\n",
       " 'fixed': 104,\n",
       " 'body': 314,\n",
       " 'single': 343,\n",
       " 'particular': 328,\n",
       " 'worldview': 13,\n",
       " 'varieties': 56,\n",
       " 'diverge': 11,\n",
       " 'widely': 280,\n",
       " 'adjectives': 14,\n",
       " 'unity': 63,\n",
       " 'fernando': 34,\n",
       " 'del': 75,\n",
       " '1889': 84,\n",
       " 'debates': 37,\n",
       " 'separation': 72,\n",
       " 'distinct': 173,\n",
       " 'entities': 52,\n",
       " 'connected': 167,\n",
       " 'uniform': 72,\n",
       " 'principles': 108,\n",
       " 'local': 314,\n",
       " 'mutual': 66,\n",
       " 'aid': 143,\n",
       " 'network': 148,\n",
       " 'communal': 23,\n",
       " 'democracy': 56,\n",
       " 'justified': 28,\n",
       " 'primary': 258,\n",
       " 'proponent': 21,\n",
       " 'future': 251,\n",
       " 'thinkers': 32,\n",
       " 'followed': 335,\n",
       " 'differ': 92,\n",
       " 'aspects': 122,\n",
       " '18th-century': 37,\n",
       " 'aims': 52,\n",
       " 'contract': 89,\n",
       " 'monetary': 37,\n",
       " 'reform': 84,\n",
       " 'credit': 54,\n",
       " 'currency': 39,\n",
       " 'regulated': 39,\n",
       " 'bank': 124,\n",
       " 'people': 613,\n",
       " 'characterised': 30,\n",
       " 'situated': 70,\n",
       " '1840': 63,\n",
       " 'goal': 108,\n",
       " 'third': 379,\n",
       " 'advocate': 58,\n",
       " 'collective': 54,\n",
       " 'means': 354,\n",
       " 'production': 255,\n",
       " 'achieved': 152,\n",
       " 'paid': 144,\n",
       " 'worked': 205,\n",
       " 'distributed': 90,\n",
       " 'need': 249,\n",
       " 'arose': 56,\n",
       " 'rejected': 128,\n",
       " 'stated': 239,\n",
       " 'advocates': 40,\n",
       " 'direct': 236,\n",
       " 'horizontal': 46,\n",
       " 'associations': 36,\n",
       " 'councils': 27,\n",
       " 'consumption': 64,\n",
       " 'guiding': 18,\n",
       " 'principle': 110,\n",
       " 'ability': 192,\n",
       " 'formulated': 32,\n",
       " 'italian': 214,\n",
       " 'section': 155,\n",
       " 'expanded': 150,\n",
       " 'theoretical': 62,\n",
       " 'work': 481,\n",
       " 'style': 191,\n",
       " 'onto': 123,\n",
       " 'dominating': 16,\n",
       " 'view': 281,\n",
       " 'branch': 134,\n",
       " 'change': 309,\n",
       " 'replacing': 74,\n",
       " 'basic': 184,\n",
       " 'action': 220,\n",
       " 'solidarity': 17,\n",
       " 'kinds': 73,\n",
       " 'external': 758,\n",
       " 'influences': 87,\n",
       " 'henry': 235,\n",
       " 'david': 277,\n",
       " 'attracted': 80,\n",
       " 'yet': 250,\n",
       " 'bohemian': 11,\n",
       " 'artists': 100,\n",
       " 'intellectuals': 29,\n",
       " 'young': 298,\n",
       " 'reclamation': 11,\n",
       " 'contemporary': 190,\n",
       " 'lawrence': 60,\n",
       " 'john': 441,\n",
       " 'authors': 142,\n",
       " 'voice': 128,\n",
       " 'noted': 233,\n",
       " 'interest': 236,\n",
       " 'momentum': 21,\n",
       " 'activist': 83,\n",
       " 'networks': 49,\n",
       " 'orientation': 37,\n",
       " 'shaped': 65,\n",
       " 'embrace': 27,\n",
       " 'continued': 317,\n",
       " 'generate': 60,\n",
       " 'times': 423,\n",
       " 'sources': 332,\n",
       " 'combining': 65,\n",
       " 'concepts': 92,\n",
       " 'approaches': 67,\n",
       " 'remained': 287,\n",
       " 'news': 130,\n",
       " 'coverage': 52,\n",
       " 'emphasizes': 29,\n",
       " 'bloc': 13,\n",
       " 'demonstrations': 29,\n",
       " 'reinforced': 34,\n",
       " 'chaos': 27,\n",
       " 'publicity': 27,\n",
       " 'fields': 142,\n",
       " 'anthropology': 17,\n",
       " 'engage': 58,\n",
       " 'actions': 148,\n",
       " 'academic': 176,\n",
       " 'today': 313,\n",
       " 'making': 361,\n",
       " 'difficult': 226,\n",
       " 'theorists': 29,\n",
       " 'relatively': 218,\n",
       " 'stable': 91,\n",
       " 'constellations': 14,\n",
       " 'consensus': 47,\n",
       " 'core': 114,\n",
       " 'commentators': 36,\n",
       " 'multiple': 209,\n",
       " 'singular': 44,\n",
       " 'gender': 42,\n",
       " 'ranks': 63,\n",
       " 'higher': 254,\n",
       " 'priority': 43,\n",
       " 'committed': 83,\n",
       " 'centralized': 25,\n",
       " 'representative': 85,\n",
       " 'etc': 151,\n",
       " 'systems': 253,\n",
       " 'slavery': 48,\n",
       " 'religions': 46,\n",
       " 'islam': 52,\n",
       " 'roman': 302,\n",
       " 'catholicism': 30,\n",
       " 'supremacy': 25,\n",
       " 'disagree': 18,\n",
       " 'methods': 175,\n",
       " 'equal': 161,\n",
       " 'liberal': 69,\n",
       " 'entails': 14,\n",
       " 'implemented': 80,\n",
       " 'questioning': 17,\n",
       " 'domination': 26,\n",
       " 'serve': 154,\n",
       " 'goals': 60,\n",
       " 'oppose': 27,\n",
       " 'secondly': 17,\n",
       " 'promote': 87,\n",
       " 'vision': 81,\n",
       " 'illustrating': 19,\n",
       " 'broad': 113,\n",
       " 'destroy': 70,\n",
       " 'gradual': 44,\n",
       " 'approach': 181,\n",
       " 'shifted': 49,\n",
       " 'course': 164,\n",
       " 'focused': 113,\n",
       " 'strikes': 48,\n",
       " 'broader': 53,\n",
       " 'array': 56,\n",
       " 'relationship': 209,\n",
       " 'controversial': 81,\n",
       " 'subject': 263,\n",
       " 'shown': 234,\n",
       " 'leon': 33,\n",
       " 'militant': 17,\n",
       " 'tendency': 55,\n",
       " 'confront': 18,\n",
       " 'forces': 256,\n",
       " 'employed': 149,\n",
       " 'terrorism': 23,\n",
       " 'assassination': 54,\n",
       " 'carried': 199,\n",
       " 'heads': 64,\n",
       " 'successful': 230,\n",
       " 'believed': 286,\n",
       " 'impetus': 13,\n",
       " 'attacks': 112,\n",
       " 'done': 224,\n",
       " 'majority': 214,\n",
       " 'place': 451,\n",
       " '1880s': 28,\n",
       " 'occurring': 72,\n",
       " '1900s': 14,\n",
       " 'decrease': 67,\n",
       " 'prevalence': 20,\n",
       " 'judicial': 45,\n",
       " 'targeting': 23,\n",
       " 'perspectives': 24,\n",
       " 'tactic': 11,\n",
       " 'attitude': 65,\n",
       " 'quite': 156,\n",
       " 'ago': 98,\n",
       " 'tyrant': 16,\n",
       " 'believing': 52,\n",
       " 'every': 363,\n",
       " 'oppression': 14,\n",
       " 'possible': 346,\n",
       " 'emma': 20,\n",
       " 'proponents': 25,\n",
       " 'argued': 148,\n",
       " 'necessary': 191,\n",
       " 'evil': 52,\n",
       " 'active': 220,\n",
       " 'strike': 60,\n",
       " 'tended': 49,\n",
       " 'overthrow': 39,\n",
       " ...}"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "TUPLE_SIZE = 6       \n",
    "TF_MASK = 2 ** 16 - 1 # Masking the 16 low bits of an integer\n",
    "from contextlib import closing\n",
    "\n",
    "def read_posting_list(inverted, w):\n",
    "  \n",
    "  with closing(MultiFileReader()) as reader:\n",
    "    locs = inverted.posting_locs[w]\n",
    "    b = reader.read(locs, inverted.df[w] * TUPLE_SIZE)\n",
    "    posting_list = []\n",
    "    for i in range(inverted.df[w]):\n",
    "      doc_id = int.from_bytes(b[i*TUPLE_SIZE:i*TUPLE_SIZE+4], 'big')\n",
    "      tf = int.from_bytes(b[i*TUPLE_SIZE+4:(i+1)*TUPLE_SIZE], 'big')\n",
    "      posting_list.append((doc_id, tf))\n",
    "    return posting_list"
   ],
   "metadata": {
    "id": "DCMAl6k41NWn"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def cos_sim(query_to_search,index):\n",
    "  ''' A function that compute the cosine similarity of a query to each relevent document\n",
    "      in the corpus. relevent document is a document with at least 1 common word with the query.\n",
    "  Parameters:\n",
    "  -----------\n",
    "    query_to_search: list of tokens.\n",
    "    index: inverted index\n",
    "  \n",
    "  Returns:\n",
    "  --------\n",
    "    list of tuples (id, score) sorted bt score.\n",
    "  '''\n",
    "    \n",
    "  epsilon = .0000001\n",
    "  docs = len(index.NF)\n",
    "  sim = defaultdict(list)\n",
    "  query_terms = Counter(query_to_search)\n",
    "  for token in np.unique(query_to_search):\n",
    "      if token in index.df.keys(): #avoid terms that do not appear in the index. \n",
    "            q_tf = query_terms[token]/len(query_to_search)\n",
    "            df=index.df[token]\n",
    "            idf = math.log((docs)/(df+epsilon),2)\n",
    "            q_tf_idf=q_tf*idf\n",
    "            pl=read_posting_list(index,token)\n",
    "            for d in pl:\n",
    "              tf=d[1]/(index.NF[d[0]][1])\n",
    "              tf_idf=tf*idf\n",
    "              sim[d[0]].append(q_tf_idf*tf_idf)\n",
    "  for k,v in sim.items():\n",
    "      valSum=builtins.sum(v)\n",
    "      norm=index.NF[k][0]/len(query_to_search)\n",
    "      sim[k]=norm*valSum\n",
    "  return get_id_title(sorted([(doc_id,score) for doc_id, score in sim.items()], key = lambda x: x[1],reverse=True)[:100])"
   ],
   "metadata": {
    "id": "LwCQBjD1wFPy"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cos_sim([\"alessandro\"],inverted_body)\n"
   ],
   "metadata": {
    "id": "Bt-vvYlo6YSH",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "outputId": "d8f499d3-9562-49b3-f502-d4bc46a2e496"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-23-72c267d593ce>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mcos_sim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"alessandro\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0minverted_body\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-22-28acb3b6985d>\u001B[0m in \u001B[0;36mcos_sim\u001B[0;34m(query_to_search, index)\u001B[0m\n\u001B[1;32m     31\u001B[0m       \u001B[0mnorm\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNF\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery_to_search\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m       \u001B[0msim\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnorm\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mvalSum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 33\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mget_id_title\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msorted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc_id\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mscore\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mdoc_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscore\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mreverse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'get_id_title' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# prepare all the data for the title index\n",
    "##########################################\n",
    "# calculate df for each term in rhe vocabulary:\n",
    "word_counts_t = doc_title_pairs.flatMap(lambda x: word_count(x[0], x[1]))\n",
    "postings_t = word_counts_t.groupByKey().mapValues(reduce_word_counts)\n",
    "w2df_t = calculate_df(postings_t)\n",
    "w2df_dict_t = w2df_t.collectAsMap()\n",
    "# caculate the NF tns the document length for each document:\n",
    "nf_t=doc_title_pairs.map(lambda x: doc_NF(x[0], x[1]))\n",
    "nf_dict_t = nf_t.collectAsMap()\n",
    "# save doc id and title for each documet\n",
    "title_id_tup=doc_title_pairs.map(lambda x:(x[1],x[0])).collectAsMap()\n",
    "# createing posting list for each term\n",
    "posting_locs_list_t = partition_postings_and_write(postings_t,'title_index').collect()\n",
    "# merge the posting locations into a single dict and run more tests (5 points)\n",
    "super_posting_locs_t = defaultdict(list)\n",
    "for posting_loc in posting_locs_list_t:\n",
    "  for k, v in posting_loc.items():\n",
    "    super_posting_locs_t[k].extend(v)"
   ],
   "metadata": {
    "id": "Klb9kPYVbXo1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create inverted index instance\n",
    "inverted_title = InvertedIndex()\n",
    "# Adding the posting locations dictionary to the inverted index\n",
    "inverted_title.posting_locs = super_posting_locs_t\n",
    "# Add the token - df dictionary to the inverted index\n",
    "inverted_title.df = w2df_dict_t\n",
    "# Add the NF dictionary to the inverted index\n",
    "inverted_title.NF=nf_dict_t\n",
    "# Add the title_dict to the inverted index\n",
    "inverted_title.title_dict=title_id_tup\n",
    "# write the global stats out\n",
    "inverted_title.write_index('title_index', 'title_index')"
   ],
   "metadata": {
    "id": "5ZwmIHYdcmuJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "w2df_dict_t"
   ],
   "metadata": {
    "id": "waxBJJ8Hv18O"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def title_binary_rank(query_to_search,index):\n",
    "\n",
    "    rank = Counter()\n",
    "    for token in np.unique(query_to_search):\n",
    "        if token in index.df.keys(): #avoid terms that do not appear in the index. \n",
    "            pl=read_posting_list(index,token)\n",
    "            for d in pl:\n",
    "              rank[d[0]]+=1\n",
    "    return get_id_title([(l,k) for k,l in sorted([(j,i) for i,j in rank.items()], reverse=True)])"
   ],
   "metadata": {
    "id": "ComgHnQxvC9r"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "title_binary_rank([\"alessandro\"],inverted_title)"
   ],
   "metadata": {
    "id": "qUhyFVgX0e8A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_id_title(list):\n",
    "  return [(id,inverted_title.title_dict[id]) for id,x in list]"
   ],
   "metadata": {
    "id": "VWyOq9HCppPa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# prepare all the data for the anchor index\n",
    "##########################################\n",
    "# calculate df for each term in rhe vocabulary:\n",
    "word_counts_a = doc_anchor_text_pairs.flatMap(lambda x: word_count(x[0], x[1]))\n",
    "postings_a = word_counts_a.groupByKey().mapValues(reduce_word_counts)\n",
    "w2df_a = calculate_df(postings_a)\n",
    "w2df_dict_a = w2df_t.collectAsMap()\n",
    "# caculate the NF tns the document length for each document:\n",
    "nf_a=doc_anchor_text_pairs.map(lambda x: doc_NF(x[0], x[1]))\n",
    "nf_dict_a = nf_a.collectAsMap()\n",
    "# createing posting list for each term\n",
    "posting_locs_list_a = partition_postings_and_write(postings_a,'anchor_index').collect()\n",
    "# merge the posting locations into a single dict and run more tests (5 points)\n",
    "super_posting_locs_a = defaultdict(list)\n",
    "for posting_loc in posting_locs_list_a:\n",
    "  for k, v in posting_loc.items():\n",
    "    super_posting_locs_a[k].extend(v)"
   ],
   "metadata": {
    "id": "9MnPR43y8imn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create inverted index instance\n",
    "inverted_anchor = InvertedIndex()\n",
    "# Adding the posting locations dictionary to the inverted index\n",
    "inverted_anchor.posting_locs = super_posting_locs_a\n",
    "# Add the token - df dictionary to the inverted index\n",
    "inverted_anchor.df = w2df_dict_a\n",
    "# Add the NF dictionary to the inverted index\n",
    "inverted_anchor.NF=nf_dict_a\n",
    "# write the global stats out\n",
    "inverted_anchor.write_index('anchor_index', 'anchor_index')"
   ],
   "metadata": {
    "id": "v7kNf76b--jk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "title_binary_rank([\"alessandro\"],inverted_anchor)"
   ],
   "metadata": {
    "id": "x4ZNWcR1_Zha"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_graph(pages):\n",
    "  ''' Compute the directed graph generated by wiki links.\n",
    "  Parameters:\n",
    "  -----------\n",
    "    pages: RDD\n",
    "      An RDD where each row consists of one wikipedia articles with 'id' and \n",
    "      'anchor_text'.\n",
    "  Returns:\n",
    "  --------\n",
    "    edges: RDD\n",
    "      An RDD where each row represents an edge in the directed graph created by\n",
    "      the wikipedia links. The first entry should the source page id and the \n",
    "      second entry is the destination page id. No duplicates should be present. \n",
    "    vertices: RDD\n",
    "      An RDD where each row represents a vetrix (node) in the directed graph \n",
    "      created by the wikipedia links. No duplicates should be present. \n",
    "  ''' \n",
    "  vertices_id=pages.map(lambda x: (x[0],))\n",
    "  rdd_anchor=pages.flatMap(lambda x: (x[1]))\n",
    "  rdd_id=rdd_anchor.map(lambda x: (x[0],))\n",
    "  all_vertices=vertices_id.union(rdd_id)\n",
    "  vertices=all_vertices.distinct()\n",
    "\n",
    "  v=pages.flatMapValues(lambda x: x)\n",
    "  edges=v.map(lambda x: (x[0],x[1][0])).distinct()\n",
    "\n",
    "  return edges, vertices"
   ],
   "metadata": {
    "id": "R6cZzgcpGD6Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# construct the graph for a small sample of (1000) pages\n",
    "edges, vertices = generate_graph(doc_anchor_text_id_pairs)\n",
    "# time the actual execution\n",
    "v_cnt, e_cnt = vertices.count(), edges.count()"
   ],
   "metadata": {
    "id": "XZpbRYuGGFlS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "edgesDF = edges.toDF(['src', 'dst']).repartition(4, 'src')\n",
    "verticesDF = vertices.toDF(['id']).repartition(4, 'id')\n",
    "g = GraphFrame(verticesDF, edgesDF)\n",
    "pr_results = g.pageRank(resetProbability=0.15, maxIter=10)\n",
    "pr = pr_results.vertices.select(\"id\", \"pagerank\")\n",
    "pr = pr.sort(col('pagerank').desc())"
   ],
   "metadata": {
    "id": "M7QeihWGIRb8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pagerank_df=pr.toPandas()\n",
    "pagerank_dict=pagerank_df.set_index('id')['pagerank'].to_dict()\n",
    "# page rank for each document\n",
    "inverted_anchor.page_score=pagerank_dict"
   ],
   "metadata": {
    "id": "a2N7dx_OJ-Qr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_pagerank(id_list):\n",
    "  return [inverted_anchor.page_score[i] for i in id_list]"
   ],
   "metadata": {
    "id": "7ziR5BiHRi2x"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "list_id=[x for x,y in cos_sim([\"alessandro\"],inverted_body)]\n",
    "get_pagerank(list_id)"
   ],
   "metadata": {
    "id": "bVrXIX1ewvhx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Paths\n",
    "# Using user page views (as opposed to spiders and automated traffic) for the \n",
    "# month of August 2021\n",
    "pv_path = 'https://dumps.wikimedia.org/other/pageview_complete/monthly/2021/2021-08/pageviews-202108-user.bz2'\n",
    "p = Path(pv_path) \n",
    "pv_name = p.name\n",
    "pv_temp = f'{p.stem}-4dedup.txt'\n",
    "pv_clean = f'{p.stem}.pkl'\n",
    "# Download the file (2.3GB) \n",
    "!wget -N $pv_path\n",
    "# Filter for English pages, and keep just two fields: article ID (3) and monthly \n",
    "# total number of page views (5). Then, remove lines with article id or page \n",
    "# view values that are not a sequence of digits.\n",
    "!bzcat $pv_name | grep \"^en\\.wikipedia\" | cut -d' ' -f3,5 | grep -P \"^\\d+\\s\\d+$\" > $pv_temp\n",
    "# Create a Counter (dictionary) that sums up the pages views for the same \n",
    "# article, resulting in a mapping from article id to total page views.\n",
    "wid2pv = Counter()\n",
    "with open(pv_temp, 'rt') as f:\n",
    "  for line in f:\n",
    "    parts = line.split(' ')\n",
    "    wid2pv.update({int(parts[0]): int(parts[1])})\n",
    "# write out the counter as binary file (pickle it)\n",
    "with open(pv_clean, 'wb') as f:\n",
    "  pickle.dump(wid2pv, f)\n",
    "# read in the counter\n",
    "# with open(pv_clean, 'rb') as f:\n",
    "#   wid2pv = pickle.loads(f.read())"
   ],
   "metadata": {
    "id": "L6eQ8LOmT3wI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open(pv_clean, 'rb') as f:\n",
    "  wid2pv = pickle.loads(f.read())"
   ],
   "metadata": {
    "id": "04NV02z6ZifW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# page views from Augoust 21, saved in inverted_anchor\n",
    "inverted_anchor.page_views=wid2pv"
   ],
   "metadata": {
    "id": "LDFqWapXas5Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_views(id_list):\n",
    "  return [inverted_anchor.page_views[i] for i in id_list]"
   ],
   "metadata": {
    "id": "sOPTF1Cnb5oe"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}